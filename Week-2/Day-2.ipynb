{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"lbnl_logo.jpg\">\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "\n",
    "# DataFrames (Cont'd)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1 - [Manipulating Columns ](#section1)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 - [Indexing &  Slicing in Pandas](#subsection1)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2 - [Uniqueness](#subsection2)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.3 - [Frequencies](#subsection3)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.4 - [Sorting](#subsection4)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.5 - [Min, Max, Range](#subsection5)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.6 - [Missing Values](#subsection6)<br>\n",
    "\n",
    "\n",
    "2 - [Booleans & Boolean Indexing](#section2)<br>\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 - [Booleans](#subsection7)<br>\n",
    "\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 - [Boolean Indexing](#subsection8)<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Frames \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by reading a new data set called \"netflix_shows\". We will use `pd.read_csv` just as we did before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix = pd.read_csv('netflix_shows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "netflix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Columns\n",
    " <a id='Section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Indexing &  Slicing  <a id='subsection1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main ways of indexing through DataFrames. We can still use our old friend, the square brackets [ : ], or we can use it with the help of two functions: **loc** and **iloc**.\n",
    "\n",
    "**loc**: uses names or labels of rows and columns.\n",
    "**iloc**: uses indices of rows and columns. You can think of *iloc* as *index-loc*.\n",
    "\n",
    "\n",
    "#### .loc[rows-label(s), columns-label(s)]\n",
    "`.loc` Helps us view and index our DataFrame. \n",
    "* It works with string labels. Notice that most of the times you will have specific column names, but our row names often come as a number. Hence the label of the rows will be a number.   \n",
    "* It can take \n",
    "    * one label __(df.loc[row-label, 'col-label-1'])__\n",
    "    * a list of labels __(df.loc[[row-label 1, row-label-2, row-label-4],['col-label-1',  'col-label-2', 'col-label-4']])__\n",
    "    * or a _slice_ of labels __(df.loc[row label-50 : row-label-100,'col-label-1': 'col-label-8'])__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can still iterate through our DataFrame (aka table) with square brackets, by identifying the cokumn name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "netflix[\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why would we want to opt out of this option and switch to `loc` and `iloc`? There are a few reasons for that, and the main being compute time. With the examples we use in this notebook, it will be impossible to notice the difference, but once we get to DataFrames with hundreds of thousands or millions of values, this will become important! \n",
    "\n",
    "On a climate care note, increased compute time leads to increased electricity and data server use, which contributes to climate change! And that's part of the reason we need to consider compute time. So let's dive into learning how to use our helpers `loc` and `iloc` to be more climate conscious."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use loc to see what are the values in row 10 in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "netflix.loc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice that if our rows were labeled with textual information, we would have to use that name instead of \"10\". In this case the label for the 10th row is indeed 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to see what are the values in row 5, 10, and 15? Let's pass 5,10, 15 into `loc` as a list of values. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "netflix.loc[[5,10,15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returned a `DataFrame` whereas the first returned a `series`. This is because on this one we selected a range of values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you use loc to see what are the values of rows 10-20? Yes, you can use a list like in the example above, but it can be quite cumbersome to have to type each number from 10 - 20. There is a better way, and this is slicing, just like we did with arrays and lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns \n",
    "\n",
    "Great! Now that you know how to index rows, let's see how we can index columns. Don't forget that we are still using `loc`, so we will have to use column labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by indexing by one column, title. Let's output all rows for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "netflix.loc[:,'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to index by only one column is by adding the column label in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "netflix.loc[:,['title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you notice the difference in output? The first output returned a `series` (another type of a data structure), and the second returned a one-column `DataFrame` because we passed a list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that here we had to specify the range of rows that we want to index that column by. We used `:` in order to return all values in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's index by more than one column. Just as before we will use a list containing our desired column labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "netflix.loc[:,['title', 'release year','user rating score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as we sliced rows, we can do the same with column. In the cell below, return all rows for columns *name* through *sodium* (inclusive of the last column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .iloc[rows_index, columns_index]\n",
    "\n",
    "Another way to index is using `.iloc`. As was mentioned above, `iloc` allows us to index using integer positions, instead of names and values of our rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "netflix.iloc[[1,3,6,8,9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the __start:stop:step__ from lists? Well we can also select a range of rows with a specified step value in our data DataFrame. In here we will take every 5th element from the 50th row to the 150th row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "netflix.iloc[50:150:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned before `iloc` works just as `loc`, but instead of using labels we use the index. Let's get all the rows in the fifth column. Don't forget that we are starting at the 0th index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "netflix.iloc[:,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you prompt it to return a one-column `DataFrame` (aka table) instead of a `series`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Uniqueness  <a id='subsection2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples below, we will be using a different DataFrame, cereal, so let's import it first. You can learn more about this data [here](https://www.kaggle.com/crawford/80-cereals)\n",
    "\n",
    "In most of our examples we will be using **[ : ]** because the cereal DataFrame is small. But feel free to practice using **loc** or **iloc** instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "# use Pandas to import cereal.csv as a DataFrame\n",
    "\n",
    "cereal = ...\n",
    "cereal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we want to find out the number of unique manufacturers in our data. The `.unique()` method allows us to check this. \n",
    "\n",
    "There are two ways to accomplish this, one is using the \"dot\" notation, and the other using brackets. For the most part, we will stick to the second method as it can be easy to run into errors.\n",
    "\n",
    "__df.column_label.unique( )__\n",
    "\n",
    "__df['column_label'].unique( )__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "print('There are ',cereal['mfr'].nunique() ,'unique manufactureres')\n",
    "print('These are: ', cereal['mfr'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we used the method `.nunique()` to tell us how _many_ unique items we have rather which items. An alternative way to compute this is __len(cereal['mfr'].nunique())__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, figure out how many unique amounts of protein levels (per serving) there are, as well as output these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "print('There are ', ...) \n",
    "print('These are: ', ...) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Frequencies  <a id='subsection3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More specifically, say we want to know how many cereals exist per manufacturers. In this case, we would like to use the `.value_counts()` method instead. This method returns the counts for the unique values in our column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal['mfr'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to find out how many cereals rows we have per each sugar level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "\n",
    "cereal['sugars'].value_counts() #SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the **-1** value for sugars? Can there be a negative sugar level? Think of what this might be representing, we will get back to it later in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Sorting  <a id='subsection4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this method sorts our values in decreasing order? What if you had an alternative sorting that you wanted to use? Maybe you want to sort by index, that is, by alphabetical order. In this case you would want to use the `sort_index()` method as seen below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal['mfr'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead you wanted to sort by counts, but in ascending (from smallest to largest) order, you can use the `.sort_values()` method instead with the argument __ascending = True__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal['mfr'].value_counts().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, let's output cereal protein levels sortex by index (in this case, the protein level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would you do that with `loc`? Remember, `loc` uses rows as the first argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Mix, Max, Range  <a id='subsection5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say that for our analysis we want to understand our cereals by the rating feature.\n",
    "\n",
    "A good starting point might be to see what the __min__ and the __max__ are for our data. We can do this by using the functions `.min()` and `.max()` respectably. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "print('Min rating is :',cereal['rating'].min())\n",
    "print('Max rating is :',cereal['rating'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the range, all you need to do is subtract the min from the max! Let's do this in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "cereal_rating_max = ...\n",
    "cereal_rating_min = ...\n",
    "rating_range = ...\n",
    "\n",
    "print(\"The range is \", rating_range) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: Use the function `round` to round these two numbers to one decimal place. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "print(\"The range rounded to one decimal place is \", round(..., ...)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Missing Values  <a id='subsection6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common problem that you will come across when analyzing data is __missing__ data. You can check if you data set contains by using the function `.isnull()`. This function returns True whenever a values is missing (Null, NaN) and False whenever it is not. We can combine this function with `.sum()` to add up all the values that are True  & False.\n",
    "\n",
    "** In Python (as in most programming languages), True is represented by 1, and False by 0. So using the `sum` function allows us to treat these True/False as numerical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that for the example above we checked for the number of missing values in each of the columns? What if you only wanted to do it for one? You can use the same methods we discuss prior, that is bracket and dot notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal['rating'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, **Null** and **NaN** are not the only ways to represent missing value. Sometimes, they can appear as 999 (commonly used in census or other data involving humans) or even -1. Remember, in one of the examples above (section on Sorting) we have found a negative value for sugar level per serving? Now we know what it meant. Most likely, there was no data available for this cereal. \n",
    "\n",
    "\n",
    "Why do you think the manufacturer did not simply input 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 GroupBy <a id='subsection7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, say that we want to find the average amount of calories for the cereals per manufacturer. We can use an operation called `.groupby()`. `.groupby()` involves a combination of splitting an object (a series or column), applying a function (for example `.sum()`,`.mean()`, or `.count()`), and combining the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal.groupby(\"mfr\")['calories'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down what happened above. We begin with a DataFrame (`cereal`) and tell pandas (our library) to group by a column (`mfr`). Then we need to specify what column (`calories`) we want to operate our desired operation (`mean`) on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, let's see what is the maximum amount of sugar level per each manufacturer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also group by more than one column! You just need to add the columns in a list. \n",
    "\n",
    "For instance, let's get the number of cereals by type and  manufacturer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal.groupby([\"type\", \"mfr\"])['name'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outcome from the groupby above resulted in a `Series`. If instead you would like to return your data as a `DataFrame` we have to use an additional brackets around the column that we are calling the action on, on this case `name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal.groupby([\"type\", \"mfr\"])[['name']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, let's use the same grouping (type and manufacturer), but instead check the max amount of calories per serving (per manfacturer per type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now check what is the max amount of sugar per each type of serving size (**cups**) per manufacturer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you moticed that almost all manufacturers use different serving sizes within one company. Can you think of why that can be beneficial sometimes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Booleans\n",
    " <a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Boolean Indexing <a id='subsection8'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we only want to look at the cereals that behave less than 100 calories. We will use __boolean indexing__ to create a DataFrame that meets this criteria. \n",
    "\n",
    "Boolean indexing allows us to define what kind of data we want to output. We can only select rows that correspond to a specific brand or choose the ones that have below a select number of calories.\n",
    "\n",
    "We will accomplish this by:\n",
    "1. Selecting the `calories` column from the DataFrame. \n",
    "2. Now we will create an array of Booleans where each value is True if and only if the value in the calories is less than 100, otherwise it will return False. You will have to use a boolean operator such as <,>, <=,>=, ==, !=, etc. on the column. \n",
    "3. Use the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if I wanted to see which cereals are manufactured by Quaker Oats, I can choose only the rows corresponding to it with boolean indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal[cereal['mfr'] == \"Q\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I wanted to have a limited amount of calories, I can specify that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal[cereal['calories'] < 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find only the cereals that have a rating above 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many cereals can you find with this rating?\n",
    "\n",
    "**Hint:** you can use our old friend `len()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, however, that just finding out the amount of calories is not enough, as sometimes companies use varied serving sizes. To account for that, we can pass two or more boolean indeces and use `&` to unite them. \n",
    "\n",
    "**Note**: if we want to use two or more specifications, we need to pass each of the in a separate set of parentheses. The structure should look like this:\n",
    "\n",
    "`dataframe[(argument 1) & (argument 2)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "cereal[((cereal['calories']) < 100) & ((cereal['cups']) < 1.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, let's output all the rows for Kellog (**\"K\"**), where the ratings for their cereals were above 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE\n",
    "\n",
    "cereal[((...) ...) & ((...) ...)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, try to only output names of these cereals (from the exercise above), ignoring the rest of the table. \n",
    "\n",
    "**Hint:** the syntax after boolean indexing will be very similar to what we used in `groupby()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHALLENGE EXERCISE\n",
    "\n",
    "cereal[((...)...) & ((...))][...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Notebook developed by: Kseniya Usovich & Karla Palos"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
